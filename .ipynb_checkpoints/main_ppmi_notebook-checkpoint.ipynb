{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d184cd",
   "metadata": {},
   "source": [
    "# <span style=\"color:#8B4513;\"> Machine Learning and RNA-Seq Data of Parkinson Disease\n",
    "</span>\n",
    "\n",
    "\n",
    "\n",
    "[<span style=\"color:#8B4513;\">Author: **Zainab Nazari**</span>](mailto:z.nazari@ebri.com)\n",
    " \n",
    " <span style=\"color:#8B4513;\">EBRI – European Brain Research Institute Rita Levi-Montalcini | MHPC - Master in High Performance Computing</span>\n",
    " \n",
    "\n",
    "\n",
    "## Introduction\n",
    "By employing machine learning in PPMI clinical data set, we can develop predictive models that aid in the early diagnosis of the disease. These models can potentially identify specific genetic markers or gene signatures that correlate with disease progression or response to treatment.\n",
    "\n",
    "## Table of Contents\n",
    "- [Matrix of Gene IDs and Counts for Pateints](#matrixcreation)\n",
    "- [Data Preprocessing STEP I](#preprocessing)\n",
    "- [Data Preprocessing STEP II](#preprocessing2)\n",
    "- [Model Training](#training)\n",
    "- [Results and Evaluation](#results)\n",
    "\n",
    "## Matrix of Gene IDs and Counts for Pateints\n",
    "- Loading the data from IR3/counts folder and extracting the associated last column (counts) of each patient file for their BL visit.\n",
    "\n",
    "\n",
    "## Data Preprocessing STEP I\n",
    "- We remove patients that have these diseases: SNCA (ENRLSNCA), GBA (ENRLGBA), LRRK2 (ENRLLRRK2).\n",
    "-  We only keep genes with the intersection of counts and quants with proteing coding and RNAincs.\n",
    "- We remove the duplicated gene IDs in which they are also lowly expressed.\n",
    "- We keep only patients with diagnosis of Health control or Parkinson disease.\n",
    "\n",
    "## Data Preprocessing STEP II\n",
    "1. Removing lowely expressed genes, by keeping only genes that had more than five counts in at least 10% of the individuals, which left us with 21,273 genes\n",
    "\n",
    "2. DESeq2: we estimated size factors, normalized the library size bias using these factors, performed independent filtering to remove lowly expressed genes using the mean of normalized counts as a filter statistic. This left us with 12,612 genes\n",
    "\n",
    "3. DESeq2: we applied a variance stabilizing transformation to accommodate the problem of unequal variance across the range of mean values.\n",
    "\n",
    "4. limma: we used control samples to estimate the batch effect of the site, that we subsequently removed in both controls and cases \n",
    "\n",
    "5. using limma: we removed further confounding effects due to sex and RIN value.\n",
    "\n",
    "## Model Training\n",
    "Build and train machine learning models on the prepared data. Explain the choice of models, feature engineering techniques, and hyperparameter tuning. Provide code and comments to walk through the model training process.\n",
    "\n",
    "## Results and Evaluation\n",
    "Present the results of the trained models, including performance metrics, accuracy, or any relevant evaluation measures. Interpret the findings and discuss the implications. Include visualizations or tables to support the results.\n",
    "\n",
    "## Conclusion\n",
    "Summarize the key findings, limitations of the analysis, and potential future work or improvements. Offer closing remarks or suggestions for further exploration.\n",
    "\n",
    "## References\n",
    "- [**Parkinson’s Progression Markers Initiative (PPMI)**](https://www.ppmi-info.org/)\n",
    "\n",
    "- [**A Machine Learning Approach to Parkinson’s Disease Blood Transcriptomics**](https://www.mdpi.com/2073-4425/13/5/727)\n",
    "\n",
    "- [**Quality Control Metrics for Whole Blood Transcriptome Analysis in the Parkinson’s Progression Markers Initiative (PPMI)**](https://www.medrxiv.org/content/10.1101/2021.01.05.21249278v1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7b8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you do not have following packages installed, uncomment instalisation.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import functools\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#!pip install dask[complete];\n",
    "# you need to run these in case dask gives you error, it might need update.\n",
    "#!pip install --upgrade pandas \"dask[complete]\"\n",
    "#python -m pip install \"dask[dataframe]\" --upgrade\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#!pip3 install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#!pip install conorm\n",
    "import conorm # for tmm normalisation\n",
    "\n",
    "#!pip install pydeseq2\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from pydeseq2.utils import load_example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba5df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the counts file in the IR3 is around 152 G, and the files are located in scratch area.\n",
    "\n",
    "path_to_files=\"/scratch/znazari/PPMI_ver_sep2022/RNA_Seq_data/star_ir3/counts/\"\n",
    "path1=Path(\"/scratch/znazari/PPMI_ver_sep2022/RNA_Seq_data/star_ir3/counts/\")\n",
    "path2 = Path(\"/home/znazari/ppmi_files/data\") # where the output data will be saved at the end.\n",
    "path3=Path(\"/scratch/znazari/PPMI_ver_sep2022/study_data/Subject_Characteristics/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86494e1a",
   "metadata": {},
   "source": [
    "<a id=\"matrixcreation\"></a>\n",
    "## Matrix of Gene IDs and Counts for Pateints\n",
    " Loading the data from IR3/counts folder and extracting the associated last column (counts) of each patient file for their BL visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b8db8",
   "metadata": {
    "tags": [
     "matrix-creation"
    ]
   },
   "outputs": [],
   "source": [
    "#reading the files which are in BL (Base line) visit.\n",
    "specific_word = 'BL'\n",
    "ending_pattern = '*.txt'\n",
    "file_pattern = f'*{specific_word}*.{ending_pattern}'\n",
    "file_paths = glob.glob(path_to_files + file_pattern)\n",
    "# 'bl.txt' is a file that ccontains the name of the files with patient, BL, IR3, counts.\n",
    "filename = 'bl.txt'\n",
    "file_path_2 = os.path.join(path_to_files, filename)\n",
    "bl_files = pd.read_csv(file_path_2,header=None)\n",
    "\n",
    "# We define a function where we can take the second phrase seperated by dot. The second phrase \n",
    "# is the patient ID. So with this functin we want to get the patient IDs from their file's name\n",
    "def function_names(fname):\n",
    "    tokens=fname.split('.')\n",
    "    return tokens[1]\n",
    "\n",
    "# we create a list with the name of the each patients.\n",
    "bl_list = [function_names(bl_files.iloc[i][0]) for i in range(len(bl_files))]\n",
    "\n",
    "# here we read all the files with with base visit(BL) from the counts folder (where we have all the files\n",
    "# for all the patients and all the visit).\n",
    "list_bl_files = [dd.read_csv(path1/bl_files.iloc[i][0],skiprows=1,delimiter='\\t') for i in range(len(bl_files))]\n",
    "\n",
    "# we get the Geneid column and convert it to dask dataframe\n",
    "pd_tmp_file = list_bl_files[3].compute()\n",
    "geneid = pd_tmp_file['Geneid']\n",
    "ddf_geneid = dd.from_pandas(geneid, npartitions=1)\n",
    "\n",
    "# we get th last columns of each file in the list\n",
    "last_columns = [ddf.iloc[:, -1:] for ddf in list_bl_files]\n",
    "\n",
    "# concatinating the list of the columns in a single file.\n",
    "single_file = dd.concat(last_columns, axis=1)\n",
    "\n",
    "# we change the name of the each columns with the patient numbers.\n",
    "single_file.columns = bl_list\n",
    "\n",
    "# here we set the Geneid column as the index of the matrix.\n",
    "ddf_new_index = single_file.set_index(ddf_geneid)\n",
    "\n",
    "# converting to pandas data frame and saving.\n",
    "ir3_counts = ddf_new_index.compute()\n",
    "ir3_counts.to_csv(path2/\"matrix_ir3_counts_bl.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab10c6",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "## Data Preprocessing STEP I\n",
    "\n",
    "- We remove patients that have these diseases: SNCA (ENRLSNCA), GBA (ENRLGBA), LRRK2 (ENRLLRRK2).\n",
    "-  We only keep genes with the intersection of counts and quants with proteing coding and RNAincs.\n",
    "- We remove the duplicated gene IDs in which they are also lowly expressed.\n",
    "- We keep only patients with diagnosis of Health control or Parkinson disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07749200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file\n",
    "read_ir3_counts = pd.read_csv(path2/\"matrix_ir3_counts_bl.csv\")\n",
    "# setting the geneid as indexing column\n",
    "read_ir3_counts.set_index('Geneid', inplace=True)\n",
    "# result with removing the after dot (.) value, i.e. the version of the geneIDs is removed.\n",
    "read_ir3_counts.index =read_ir3_counts.index.str.split('.').str[0]\n",
    "\n",
    "\n",
    "#here we delete the duplicated gene IDs, first we find them then remove them from the gene IDs\n",
    "# as they are duplicated and also they are very lowly expressed either zero or one in rare caes.\n",
    "\n",
    "# Check for duplicate index values\n",
    "is_duplicate = read_ir3_counts.index.duplicated()\n",
    "\n",
    "# Display the duplicate index values\n",
    "duplicate_indices = read_ir3_counts.index[is_duplicate]\n",
    "\n",
    "# drop them and display the result\n",
    "to_be_deleted = list(duplicate_indices)\n",
    "read_ir3_counts = read_ir3_counts.drop(to_be_deleted)\n",
    "\n",
    "# we read the file where we have an intersection of geneIDs in IR3, counts, quant\n",
    "intersect = pd.read_csv(path2/\"intersect_IR3_ENG_IDs_LincRNA_ProtCoding_counts_quant_gene_transcript_only_tot_intsersect.txt\")\n",
    "intersection = read_ir3_counts.index.intersection(intersect['[IR3_gene_counts] and [IR3_quant_gene] and [IR3_quant_trans] and [lncRNA+ProtCod]: '])\n",
    "filtered_read_ir3_counts = read_ir3_counts.loc[intersection]\n",
    "filtered_read_ir3_counts\n",
    "\n",
    "# reading the file which contains diagnosis\n",
    "diago=pd.read_csv(path3/\"Participant_Status.csv\", header=None )\n",
    "diago1=diago.rename(columns=diago.iloc[0]).drop(diago.index[0]).reset_index(drop=True)\n",
    "\n",
    "#this is to remove patients that have these diseases: SNCA (ENRLSNCA), GBA (ENRLGBA), LRRK2 (ENRLLRRK2)\n",
    "filtered_SNCA_GBA_LRRK2 = diago1[(diago1['ENRLSNCA'] == \"0\")& (diago1['ENRLGBA'] == \"0\")& (diago1['ENRLLRRK2'] == \"0\")]\n",
    "\n",
    "#patients with their diagnosis\n",
    "patinets_diagnosis = filtered_SNCA_GBA_LRRK2[['PATNO','COHORT_DEFINITION']].reset_index(drop=True)\n",
    "\n",
    "# Define the particular names to keep\n",
    "names_to_keep = ['Healthy Control', \"Parkinson's Disease\"]\n",
    "\n",
    "# Filter the dataframe based on the specified names\n",
    "PK_HC_pateints = patinets_diagnosis[patinets_diagnosis['COHORT_DEFINITION'].isin(names_to_keep)]\n",
    "\n",
    "# Get the list of patient IDs with diagnosis from the second dataframe\n",
    "patient_ids_with_diagnosis = PK_HC_pateints['PATNO']\n",
    "list_patients=list(patient_ids_with_diagnosis)\n",
    "\n",
    "# Filter the columns in the first dataframe based on patient IDs with diagnosis\n",
    "rna_filtered = filtered_read_ir3_counts.filter(items=list_patients)\n",
    "rna_filtered.to_csv(path2/'ir3_rna.csv', index=False)\n",
    "\n",
    "# we keep only the patients that are common in the two dataframes:\n",
    "common_patient_ids = list(set(PK_HC_pateints['PATNO']).intersection(df_filtered.columns))\n",
    "patient11_filtered = PK_HC_pateints[PK_HC_pateints['PATNO'].isin(common_patient_ids)]\n",
    "patient11_filtered.reset_index(drop=True)\n",
    "\n",
    "# we save the output into data folder\n",
    "patient11_filtered.to_csv(path2/'patients_HC_PK_diagnosis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f23fb",
   "metadata": {},
   "source": [
    "<a id=\"preprocessin2\"></a>\n",
    "## Data Preprocessing 2\n",
    "\n",
    "1. Removing lowely expressed genes, by keeping only genes that had more than five counts in at least 10% of the individuals, which left us with 21,273 genes\n",
    "\n",
    "2. DESeq2: we estimated size factors, normalized the library size bias using these factors, performed independent filtering to remove lowly expressed genes using the mean of normalized counts as a filter statistic. This left us with 12,612 genes\n",
    "\n",
    "3. DESeq2: we applied a variance stabilizing transformation to accommodate the problem of unequal variance across the range of mean values.\n",
    "\n",
    "4. limma: we used control samples to estimate the batch effect of the site, that we subsequently removed in both controls and cases \n",
    "\n",
    "5. limma: we removed further confounding effects due to sex and RIN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6376df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = pd.read_csv(path2/'ir3_rna.csv')\n",
    "diagnosis = pd.read_csv(path2/'patients_HC_PK_diagnosis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5d06c",
   "metadata": {},
   "source": [
    "<a id=\"training\"></a>\n",
    "## Model Training \n",
    "\n",
    "Build and train machine learning models on the prepared data. Explain the choice of models, feature engineering techniques, and hyperparameter tuning. Provide code and comments to walk through the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc5964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27602ca3",
   "metadata": {},
   "source": [
    "<a id=\"results\"></a>\n",
    "## Results and Evaluation \n",
    "\n",
    "Present the results of the trained models, including performance metrics, accuracy, or any relevant evaluation measures. Interpret the findings and discuss the implications. Include visualizations or tables to support the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d5e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
