{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d184cd",
   "metadata": {},
   "source": [
    "# <span style=\"color:#8B4513;\"> Machine Learning and RNA-Seq Data of Parkinson Disease\n",
    "</span>\n",
    "\n",
    "\n",
    "\n",
    "[<span style=\"color:#8B4513;\">Author: **Zainab Nazari**</span>](mailto:z.nazari@ebri.com)\n",
    " \n",
    " <span style=\"color:#8B4513;\">EBRI – European Brain Research Institute Rita Levi-Montalcini | MHPC - Master in High Performance Computing</span>\n",
    " \n",
    "\n",
    "\n",
    "## Introduction\n",
    "By employing machine learning in PPMI clinical data set, we can develop predictive models that aid in the early diagnosis of the disease. These models can potentially identify specific genetic markers or gene signatures that correlate with disease progression or response to treatment.\n",
    "\n",
    "## Table of Contents\n",
    "- [Matrix of Gene IDs and Counts for Pateints](#matrixcreation)\n",
    "- [Data Preprocessing STEP I](#preprocessing)\n",
    "- [Data Preprocessing STEP II](#preprocessing2)\n",
    "- [Model Training](#training)\n",
    "- [Results and Evaluation](#results)\n",
    "\n",
    "## Matrix of Gene IDs and Counts for Pateints\n",
    "- Loading the data from IR3/counts folder and extracting the associated last column (counts) of each patient file for their BL visit.\n",
    "\n",
    "\n",
    "## Data Preprocessing STEP I\n",
    "- We remove patients that have these diseases: SNCA (ENRLSNCA), GBA (ENRLGBA), LRRK2 (ENRLLRRK2).\n",
    "-  We only keep genes with the intersection of counts and quants with proteing coding and RNAincs.\n",
    "- We remove the duplicated gene IDs in which they are also lowly expressed.\n",
    "- We keep only patients with diagnosis of Health control or Parkinson disease.\n",
    "\n",
    "## Data Preprocessing STEP II\n",
    "1. Removing lowely expressed genes, by keeping only genes that had more than five counts in at least 10% of the individuals, which left us with 21,273 genes\n",
    "\n",
    "2. DESeq2: we estimated size factors, normalized the library size bias using these factors, performed independent filtering to remove lowly expressed genes using the mean of normalized counts as a filter statistic. This left us with 12,612 genes\n",
    "\n",
    "3. DESeq2: we applied a variance stabilizing transformation to accommodate the problem of unequal variance across the range of mean values.\n",
    "\n",
    "4. limma: we used control samples to estimate the batch effect of the site, that we subsequently removed in both controls and cases \n",
    "\n",
    "5. using limma: we removed further confounding effects due to sex and RIN value.\n",
    "\n",
    "## Model Training\n",
    "Build and train machine learning models on the prepared data. Explain the choice of models, feature engineering techniques, and hyperparameter tuning. Provide code and comments to walk through the model training process.\n",
    "\n",
    "## Results and Evaluation\n",
    "Present the results of the trained models, including performance metrics, accuracy, or any relevant evaluation measures. Interpret the findings and discuss the implications. Include visualizations or tables to support the results.\n",
    "\n",
    "## Conclusion\n",
    "Summarize the key findings, limitations of the analysis, and potential future work or improvements. Offer closing remarks or suggestions for further exploration.\n",
    "\n",
    "## References\n",
    "- [**Parkinson’s Progression Markers Initiative (PPMI)**](https://www.ppmi-info.org/)\n",
    "\n",
    "- [**A Machine Learning Approach to Parkinson’s Disease Blood Transcriptomics**](https://www.mdpi.com/2073-4425/13/5/727)\n",
    "\n",
    "- [**Quality Control Metrics for Whole Blood Transcriptome Analysis in the Parkinson’s Progression Markers Initiative (PPMI)**](https://www.medrxiv.org/content/10.1101/2021.01.05.21249278v1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7b8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you do not have following packages installed, uncomment instalisation.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import functools\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#!pip install dask[complete];\n",
    "# you need to run these in case dask gives you error, it might need update.\n",
    "#!pip install --upgrade pandas \"dask[complete]\"\n",
    "#python -m pip install \"dask[dataframe]\" --upgrade\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#!pip3 install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#!pip install conorm\n",
    "import conorm # for tmm normalisation\n",
    "\n",
    "#!pip install pydeseq2\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from pydeseq2.utils import load_example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba5df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the counts file in the IR3 is around 152 G, and the files are located in scratch area.\n",
    "\n",
    "path_to_files=\"/scratch/znazari/PPMI_ver_sep2022/RNA_Seq_data/star_ir3/counts/\"\n",
    "path1=Path(\"/scratch/znazari/PPMI_ver_sep2022/RNA_Seq_data/star_ir3/counts/\")\n",
    "path2 = Path(\"/home/znazari/data\") # where the output data will be saved at the end.\n",
    "path3=Path(\"/scratch/znazari/PPMI_ver_sep2022/study_data/Subject_Characteristics/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86494e1a",
   "metadata": {},
   "source": [
    "<a id=\"matrixcreation\"></a>\n",
    "## Matrix of Gene IDs and Counts for Pateints\n",
    " Loading the data from IR3/counts folder and extracting the associated last column (counts) of each patient file for their BL visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403b8db8",
   "metadata": {
    "tags": [
     "matrix-creation"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/znazari/anaconda3/lib/python3.9/site-packages/dask/dataframe/multi.py:1291: UserWarning: Concatenating dataframes with unknown divisions.\n",
      "We're assuming that the indices of each dataframes are \n",
      " aligned. This assumption is not generally safe.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#reading the files which are in BL (Base line) visit.\n",
    "specific_word = 'BL'\n",
    "ending_pattern = '*.txt'\n",
    "file_pattern = f'*{specific_word}*.{ending_pattern}'\n",
    "file_paths = glob.glob(path_to_files + file_pattern)\n",
    "# 'bl.txt' is a file that ccontains the name of the files with patient, BL, IR3, counts.\n",
    "filename = 'bl.txt'\n",
    "file_path_2 = os.path.join(path_to_files, filename)\n",
    "bl_files = pd.read_csv(file_path_2,header=None)\n",
    "\n",
    "# We define a function where we can take the second phrase seperated by dot. The second phrase \n",
    "# is the patient ID. So with this functin we want to get the patient IDs from their file's name\n",
    "def function_names(fname):\n",
    "    tokens=fname.split('.')\n",
    "    return tokens[1]\n",
    "\n",
    "# we create a list with the name of the each patients.\n",
    "bl_list = [function_names(bl_files.iloc[i][0]) for i in range(len(bl_files))]\n",
    "\n",
    "# here we read all the files with with base visit(BL) from the counts folder (where we have all the files\n",
    "# for all the patients and all the visit).\n",
    "list_bl_files = [dd.read_csv(path1/bl_files.iloc[i][0],skiprows=1,delimiter='\\t') for i in range(len(bl_files))]\n",
    "\n",
    "\n",
    "# we get th last columns of each file in the list\n",
    "last_columns = [ddf.iloc[:, -1:] for ddf in list_bl_files]\n",
    "\n",
    "# concatinating the list of the columns in a single file.\n",
    "single_file = dd.concat(last_columns, axis=1)\n",
    "\n",
    "# we change the name of the each columns with the patient numbers.\n",
    "single_file.columns = bl_list\n",
    "\n",
    "# we get the Geneid column and convert it to dask dataframe\n",
    "pd_tmp_file = list_bl_files[3].compute()\n",
    "geneid = pd_tmp_file['Geneid']\n",
    "ddf_geneid = dd.from_pandas(geneid, npartitions=1)\n",
    "\n",
    "# here we set the Geneid column as the index of the matrix.\n",
    "ddf_new_index = single_file.set_index(ddf_geneid)\n",
    "\n",
    "# converting to pandas data frame and saving.\n",
    "ir3_counts = ddf_new_index.compute()\n",
    "ir3_counts.to_csv(path2/\"matrix_ir3_counts_bl.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab10c6",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "## Data Preprocessing STEP I\n",
    "\n",
    "- We remove patients that have these diseases: SNCA (ENRLSNCA), GBA (ENRLGBA), LRRK2 (ENRLLRRK2).\n",
    "- dopamin drug using\n",
    "-  We only keep genes with the intersection of counts and quants with proteing coding and RNAincs.\n",
    "- We remove the duplicated gene IDs in which they are also lowly expressed.\n",
    "- We keep only patients with diagnosis of Health control or Parkinson disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07749200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file\n",
    "read_ir3_counts = pd.read_csv(path2/\"matrix_ir3_counts_bl.csv\")\n",
    "# setting the geneid as indexing column\n",
    "read_ir3_counts.set_index('Geneid', inplace=True)\n",
    "# result with removing the after dot (.) value, i.e. the version of the geneIDs is removed.\n",
    "read_ir3_counts.index =read_ir3_counts.index.str.split('.').str[0]\n",
    "\n",
    "\n",
    "#here we delete the duplicated gene IDs, first we find them then remove them from the gene IDs\n",
    "# as they are duplicated and also they are very lowly expressed either zero or one in rare caes.\n",
    "\n",
    "# Check for duplicate index values\n",
    "is_duplicate = read_ir3_counts.index.duplicated()\n",
    "\n",
    "#  DUPLICATED STILL THERE!!! CHECK.\n",
    "# Display the duplicate index values\n",
    "duplicate_indices = read_ir3_counts.index[is_duplicate]\n",
    "\n",
    "# drop them and display the result\n",
    "to_be_deleted = list(duplicate_indices)\n",
    "read_ir3_counts = read_ir3_counts.drop(to_be_deleted)\n",
    "\n",
    "# we read the file where we have an intersection of geneIDs in IR3, counts, quant\n",
    "intersect = pd.read_csv(path2/\"intersect_IR3_ENG_IDs_LincRNA_ProtCoding_counts_quant_gene_transcript_only_tot_intsersect.txt\")\n",
    "intersection = read_ir3_counts.index.intersection(intersect['[IR3_gene_counts] and [IR3_quant_gene] and [IR3_quant_trans] and [lncRNA+ProtCod]: '])\n",
    "filtered_read_ir3_counts = read_ir3_counts.loc[intersection]\n",
    "filtered_read_ir3_counts\n",
    "\n",
    "# reading the file which contains diagnosis\n",
    "diago=pd.read_csv(path3/\"Participant_Status.csv\", header=None )\n",
    "diago1=diago.rename(columns=diago.iloc[0]).drop(diago.index[0]).reset_index(drop=True)\n",
    "\n",
    "#this is to remove patients that have these diseases: SNCA (ENRLSNCA), GBA (ENRLGBA), LRRK2 (ENRLLRRK2)\n",
    "filtered_SNCA_GBA_LRRK2 = diago1[(diago1['ENRLSNCA'] == \"0\")& (diago1['ENRLGBA'] == \"0\")& (diago1['ENRLLRRK2'] == \"0\")]\n",
    "\n",
    "#patients with their diagnosis\n",
    "patinets_diagnosis = filtered_SNCA_GBA_LRRK2[['PATNO','COHORT_DEFINITION']].reset_index(drop=True)\n",
    "\n",
    "# Define the particular names to keep\n",
    "names_to_keep = ['Healthy Control', \"Parkinson's Disease\"]\n",
    "\n",
    "\n",
    "# Filter the dataframe based on the specified names\n",
    "PK_HC_pateints = patinets_diagnosis[patinets_diagnosis['COHORT_DEFINITION'].isin(names_to_keep)]\n",
    "\n",
    "# Get the list of patient IDs with diagnosis from the second dataframe\n",
    "patient_ids_with_diagnosis = PK_HC_pateints['PATNO']\n",
    "list_patients=list(patient_ids_with_diagnosis)\n",
    "\n",
    "# Filter the columns in the first dataframe based on patient IDs with diagnosis\n",
    "rna_filtered = filtered_read_ir3_counts.filter(items=list_patients)\n",
    "rna_filtered.to_csv(path2/'ir3_rna.csv', index=False)\n",
    "\n",
    "# we keep only the patients that are common in the two dataframes:\n",
    "common_patient_ids = list(set(PK_HC_pateints['PATNO']).intersection(rna_filtered.columns))\n",
    "patient11_filtered = PK_HC_pateints[PK_HC_pateints['PATNO'].isin(common_patient_ids)]\n",
    "patient11_filtered.reset_index(drop=True)\n",
    "\n",
    "# we save the output into data folder\n",
    "patient11_filtered.to_csv(path2/'patients_HC_PK_diagnosis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0351e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_dopomine = pd.read_csv(path2/'Patient_IDs_taking_dopamine_drugs.txt',delimiter='\\t',  header=None)\n",
    "patient_dopomine = patient_dopomine.rename(columns={0: 'Pateint IDs'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f23fb",
   "metadata": {},
   "source": [
    "<a id=\"preprocessin2\"></a>\n",
    "## Data Preprocessing STEP II\n",
    "\n",
    "1. Removing lowely expressed genes, by keeping only genes that had more than five counts in at least 10% of the individuals, which left us with 21,273 genes\n",
    "\n",
    "2. DESeq2: we estimated size factors, normalized the library size bias using these factors, performed independent filtering to remove lowly expressed genes using the mean of normalized counts as a filter statistic. This left us with 12,612 genes\n",
    "\n",
    "3. DESeq2: we applied a variance stabilizing transformation to accommodate the problem of unequal variance across the range of mean values.\n",
    "\n",
    "4. limma: we used control samples to estimate the batch effect of the site, that we subsequently removed in both controls and cases \n",
    "\n",
    "5. limma: we removed further confounding effects due to sex and RIN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37bdcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_remove = patient_dopomine['Pateint IDs'].tolist()\n",
    "ids_to_remove\n",
    "strings = [str(num) for num in ids_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6376df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = pd.read_csv(path2/'ir3_rna.csv')\n",
    "diagnosis = pd.read_csv(path2/'patients_HC_PK_diagnosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "215699b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3000</th>\n",
       "      <th>3001</th>\n",
       "      <th>3002</th>\n",
       "      <th>3003</th>\n",
       "      <th>3004</th>\n",
       "      <th>3006</th>\n",
       "      <th>3007</th>\n",
       "      <th>3008</th>\n",
       "      <th>3009</th>\n",
       "      <th>3010</th>\n",
       "      <th>...</th>\n",
       "      <th>4121</th>\n",
       "      <th>4122</th>\n",
       "      <th>4123</th>\n",
       "      <th>4124</th>\n",
       "      <th>4125</th>\n",
       "      <th>4126</th>\n",
       "      <th>4135</th>\n",
       "      <th>4136</th>\n",
       "      <th>4139</th>\n",
       "      <th>41410</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>815</td>\n",
       "      <td>879</td>\n",
       "      <td>855</td>\n",
       "      <td>1194</td>\n",
       "      <td>770</td>\n",
       "      <td>779</td>\n",
       "      <td>980</td>\n",
       "      <td>945</td>\n",
       "      <td>1185</td>\n",
       "      <td>...</td>\n",
       "      <td>529</td>\n",
       "      <td>1406</td>\n",
       "      <td>851</td>\n",
       "      <td>653</td>\n",
       "      <td>606</td>\n",
       "      <td>1183</td>\n",
       "      <td>536</td>\n",
       "      <td>426</td>\n",
       "      <td>754</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1869</td>\n",
       "      <td>1510</td>\n",
       "      <td>1438</td>\n",
       "      <td>1593</td>\n",
       "      <td>2418</td>\n",
       "      <td>1925</td>\n",
       "      <td>1446</td>\n",
       "      <td>1607</td>\n",
       "      <td>1923</td>\n",
       "      <td>2210</td>\n",
       "      <td>...</td>\n",
       "      <td>1275</td>\n",
       "      <td>2529</td>\n",
       "      <td>1677</td>\n",
       "      <td>1681</td>\n",
       "      <td>1428</td>\n",
       "      <td>2008</td>\n",
       "      <td>1378</td>\n",
       "      <td>1037</td>\n",
       "      <td>1390</td>\n",
       "      <td>1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512</td>\n",
       "      <td>367</td>\n",
       "      <td>460</td>\n",
       "      <td>444</td>\n",
       "      <td>581</td>\n",
       "      <td>522</td>\n",
       "      <td>504</td>\n",
       "      <td>488</td>\n",
       "      <td>621</td>\n",
       "      <td>605</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>682</td>\n",
       "      <td>410</td>\n",
       "      <td>432</td>\n",
       "      <td>473</td>\n",
       "      <td>601</td>\n",
       "      <td>478</td>\n",
       "      <td>343</td>\n",
       "      <td>291</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30419</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30420</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30421</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30422</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30424 rows × 583 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       3000  3001  3002  3003  3004  3006  3007  3008  3009  3010  ...  4121  \\\n",
       "0        40    13    87    11    27    22    25    24    33    14  ...    15   \n",
       "1         4     0    28     2    10     0     2     0     0     2  ...     3   \n",
       "2       563   815   879   855  1194   770   779   980   945  1185  ...   529   \n",
       "3      1869  1510  1438  1593  2418  1925  1446  1607  1923  2210  ...  1275   \n",
       "4       512   367   460   444   581   522   504   488   621   605  ...   320   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "30419     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "30420     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "30421     2     0    11     1     5     0     0     0     0     1  ...     0   \n",
       "30422     1     0     8     0     5     1     0     0     1     0  ...     0   \n",
       "30423     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "       4122  4123  4124  4125  4126  4135  4136  4139  41410  \n",
       "0        26    15    16    19    41    11    16    15     15  \n",
       "1         0     0     2     8     1     1     5     1      0  \n",
       "2      1406   851   653   606  1183   536   426   754    645  \n",
       "3      2529  1677  1681  1428  2008  1378  1037  1390   1630  \n",
       "4       682   410   432   473   601   478   343   291    529  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...    ...  \n",
       "30419     0     0     0     0     0     0     0     0      0  \n",
       "30420     0     0     0     0     0     0     0     0      0  \n",
       "30421     0     0     0     4     1     2     2     0      0  \n",
       "30422     0     0     0     3     1     0     0     1      0  \n",
       "30423     0     0     0     0     0     0     0     0      0  \n",
       "\n",
       "[30424 rows x 583 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = [col for col in rna.columns if not any(string in col for string in strings)]\n",
    "rna = rna[new_columns]\n",
    "rna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5d06c",
   "metadata": {},
   "source": [
    "<a id=\"training\"></a>\n",
    "## Model Training \n",
    "\n",
    "Build and train machine learning models on the prepared data. Explain the choice of models, feature engineering techniques, and hyperparameter tuning. Provide code and comments to walk through the model training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27602ca3",
   "metadata": {},
   "source": [
    "<a id=\"results\"></a>\n",
    "## Results and Evaluation \n",
    "\n",
    "Present the results of the trained models, including performance metrics, accuracy, or any relevant evaluation measures. Interpret the findings and discuss the implications. Include visualizations or tables to support the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d5e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
