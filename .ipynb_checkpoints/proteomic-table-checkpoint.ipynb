{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6099c14b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Proteomics CSF Data from PPMI \n",
    "\n",
    "**Cerebrospinal Fluid (CSF) proteomic**  is a clear fluid that surrounds the brain and spinal cord. It provides a protective cushion for the brain and helps remove waste products.\n",
    "\n",
    "- We organise CSF data from Parkinson's disease and healthy patients. The proteomic data are in 7 files Project_151_pQTL_in_CSF_{}_of_7_Batch_Corrected_.csv, that we need to combine them together. We save the final single DataFrame at the end.\n",
    "\n",
    "- The collected CSF can be analyzed to look for various markers, proteins, or other substances that may be indicative of neurological conditions, including Parkinson's disease.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53b3a87",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c33c11d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# The pathes (Directories) to the data\n",
    "path = Path(\"/home/znazari/data/open_proteomic/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214726e0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the base file name and path\n",
    "base_file_name = \"Project_151_pQTL_in_CSF_{}_of_7_Batch_Corrected_.csv\"\n",
    "\n",
    "# Number of files\n",
    "num_files = 7\n",
    "\n",
    "# List to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the file indices and read each file\n",
    "for file_index in range(1, num_files + 1):\n",
    "    file_name = base_file_name.format(file_index)\n",
    "    file_path = path / file_name\n",
    "    \n",
    "    # Check if the file exists before attempting to read it\n",
    "    if file_path.is_file():\n",
    "        # Read the CSV file and append it to the list\n",
    "        df = pd.read_csv(file_path, delimiter=',')\n",
    "        dfs.append(df)\n",
    "    else:\n",
    "        print(f\"File {file_name} not found.\")\n",
    "        \n",
    "# Concat files together\n",
    "result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Filter out patients diagnosed as Prodromal\n",
    "result_df = result_df[result_df['COHORT'] != 'Prodromal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b1adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients with their diagnosis \n",
    "patient_diagnosis_df = result_df[['PATNO', 'COHORT']]\n",
    "\n",
    "# Drop duplicate rows based on 'PATNO'\n",
    "unique_patient_diagnosis_df = patient_diagnosis_df.drop_duplicates(subset='PATNO')\n",
    "unique_patient_diagnosis_dff = unique_patient_diagnosis_df.copy()\n",
    "\n",
    "# Pivot the DataFrame to get the desired format\n",
    "result_pivot = result_df.pivot(index='TESTNAME', columns='PATNO', values='TESTVALUE')\n",
    "\n",
    "# Transpose the dataframe \n",
    "patients_csf_t=result_pivot.T\n",
    "\n",
    "# Fix indexing\n",
    "new_patients_csf = patients_csf_t.reset_index().rename(columns={'index': 'PATNO'})\n",
    "\n",
    "# Convert int patient numbers to str\n",
    "new_patients_csf['PATNO'] = new_patients_csf['PATNO'].astype(str)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'COHORT' column\n",
    "label = label_encoder.fit_transform(unique_patient_diagnosis_df['COHORT'])\n",
    "\n",
    "# Set the label for parkinson's disease and healthy control\n",
    "unique_patient_diagnosis_dff.loc[:, 'COHORT'] = label\n",
    "\n",
    "# Reset the indices\n",
    "new_diagnosis = unique_patient_diagnosis_dff.reset_index(drop=True)\n",
    "\n",
    "new_diagnosis['PATNO'] = new_diagnosis['PATNO'].astype(str)\n",
    "\n",
    "# Merge the proteomic dataframe with diagnosis\n",
    "final_proteomic_patients = pd.merge(new_diagnosis, new_patients_csf, how='inner', on='PATNO')\n",
    "\n",
    "final_proteomic_patients.to_csv(path/'final_proteomic_patients.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb28e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update : 2024-02-05\n"
     ]
    }
   ],
   "source": [
    "# Get the current date\n",
    "current_date = datetime.now().date()\n",
    "\n",
    "# Print the current date\n",
    "print(\"Last update :\", current_date)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
